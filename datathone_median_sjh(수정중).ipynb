{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "uFRMmq6Ndr99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "5JSWzZleccsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aCuiWsJadjj"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle --upgrade\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls -1ha kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c mercari-price-suggestion-challenge"
      ],
      "metadata": {
        "id": "iqCd-HYwckj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 확인\n",
        "!ls\n",
        "# 압축 풀기\n",
        "!unzip mercari-price-suggestion-challenge\n",
        "!unzip test_stg2.tsv"
      ],
      "metadata": {
        "id": "W-_n1iI6c3QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud\n",
        "!pip install koreanize-matplotlib\n",
        "#!pip install lightgbm\n",
        "!pip install xgboost"
      ],
      "metadata": {
        "id": "2pV-walec7ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from scipy.sparse import hstack\n",
        "import lightgbm as lgb\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import koreanize_matplotlib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.svm import SVR\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "I5cQGYFxtPIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install 7-zip\n",
        "!apt-get install p7zip-full\n",
        "\n",
        "# Step 2: Unzip the .7z file\n",
        "!7z x /content/train.tsv.7z -o/content/\n",
        "!7z x /content/test.tsv.7z -o/content/\n",
        "!7z x /content/test_stg2.tsv.7z -o/content/\n",
        "\n",
        "\n",
        "# Step 3: Read the unzipped files with pandas\n",
        "#import pandas as pd\n",
        "\n",
        "train = pd.read_csv(\"/content/train.tsv\", sep='\\t', encoding='utf-8')\n",
        "test = pd.read_csv(\"/content/test.tsv\", sep='\\t', encoding='utf-8')\n",
        "test_stg2 = pd.read_csv(\"/content/test_stg2.tsv\", sep='\\t', encoding='utf-8')\n",
        "\n",
        "# Display the first few rows of the train and test datasets\n",
        "print(train.head())\n",
        "print(test.head())\n",
        "print(test_stg2.head())"
      ],
      "metadata": {
        "id": "ExveRL4wdnMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 살펴보기"
      ],
      "metadata": {
        "id": "s2aTbUZjdmEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "t6yOAKQmd951"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "id": "q-CYMuofeNWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_stg2.head()"
      ],
      "metadata": {
        "id": "RlDxt1m3zxCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "DH5_n1EqeOhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.info()"
      ],
      "metadata": {
        "id": "pdkY9l0OePlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_stg2.info()"
      ],
      "metadata": {
        "id": "9_lSBBS-z0ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "print(test.shape)\n",
        "print(test_stg2.shape)"
      ],
      "metadata": {
        "id": "yDdy77BJeRAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 가독성 있게\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "train.describe()"
      ],
      "metadata": {
        "id": "PzpYYnv4eR9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test.describe()"
      ],
      "metadata": {
        "id": "y8AiPtYAeTqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_stg2.describe()"
      ],
      "metadata": {
        "id": "Lg2d1Wny0Blv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().sum()  #브랜드 카테고리 설명 결측치가 있다.\n",
        "## category_name, brand_name에서 대부분의 결측치가 보였다.\n",
        "## item_description은 6개니까 제거하는 방향으로 가야겠다.\n",
        "\n",
        "## 저 데이터들을 마냥 제거하기엔 너무 많다. 다른 방법이 있을 것이다.\n",
        "## 우선 EDA에 걸림돌이 되지 않는 선에서 분석을 진행한다."
      ],
      "metadata": {
        "id": "tre3w4NB1ueJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.isnull().sum()"
      ],
      "metadata": {
        "id": "w9DU8UfP1vlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_stg2.isnull().sum()"
      ],
      "metadata": {
        "id": "Ygo6SvQa0JTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5DtzGUgnf5vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리"
      ],
      "metadata": {
        "id": "I7b5Uw6geU9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 레이블 인코딩 함수\n",
        "def label_encode(df, columns):\n",
        "    le = LabelEncoder()\n",
        "    for col in columns:\n",
        "        df[col] = le.fit_transform(df[col].astype(str))\n",
        "    return df, le"
      ],
      "metadata": {
        "id": "OuoY_keweY8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## RMSLE 계산\n",
        "def rmsle(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_log_error(y_true, y_pred))"
      ],
      "metadata": {
        "id": "N9AIc6FBwEOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 함수들\n",
        "\n",
        "# 입력 텍스트를 전처리하는 함수\n",
        "def preprocess(Input_text):\n",
        "    # 자주 사용되는 정규 표현식 패턴을 미리 컴파일\n",
        "    HTML_CLEANER = re.compile('<.*?>')\n",
        "    EMAIL_CLEANER = re.compile(r'\\S*@\\S*\\s?')\n",
        "    URL_CLEANER = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    PARENTHESES_CLEANER = re.compile(r\"[\\(\\[].*?[\\)\\]]\")\n",
        "    WORD_COLON_CLEANER = re.compile(r'\\w+:\\s?')\n",
        "    NUMBER_CLEANER = re.compile(r'[0-9]+')\n",
        "    NON_ALPHA_CLEANER = re.compile(r'[^a-zA-Z]+')\n",
        "\n",
        "    # 입력 텍스트의 처음 60개 단어만 사용\n",
        "    cleantext = ' '.join([w for w in Input_text.split()[:60]])\n",
        "\n",
        "    # HTML 태그, 이메일, URL 제거\n",
        "    cleantext = HTML_CLEANER.sub('', cleantext)\n",
        "    cleantext = EMAIL_CLEANER.sub(' ', cleantext)\n",
        "    cleantext = URL_CLEANER.sub(' ', cleantext)\n",
        "\n",
        "    # 괄호 안의 내용 제거\n",
        "    cleantext = PARENTHESES_CLEANER.sub(\"\", cleantext)\n",
        "\n",
        "    # 단어 뒤의 콜론 제거\n",
        "    cleantext = WORD_COLON_CLEANER.sub('', cleantext)\n",
        "\n",
        "    # 축약형 처리\n",
        "    contractions = {\n",
        "        r\"\\'m\": \" am\", r\"n\\'t\": \" not\", r\"\\'t\": \" not\", r\"\\'s\": \" is\",\n",
        "        r\"\\'ve\": \" have\", r\"\\'re\": \" are\", r\"\\'ll\": \" will\",\n",
        "        r\"won\\'t\": \"will not\", r\"can\\'t\": \"can not\", r\"\\'d\": \" would\",\n",
        "        r\"y\\'all\": \"you all\", r\"ain\\'t\": \"is not\", r\"aren\\'t\": \"are not\",\n",
        "        r\"couldn\\'t\": \"could not\", r\"didn\\'t\": \"did not\", r\"doesn\\'t\": \"does not\",\n",
        "        r\"hadn\\'t\": \"had not\", r\"hasn\\'t\": \"has not\", r\"haven\\'t\": \"have not\",\n",
        "        r\"he\\'d\": \"he would\", r\"he\\'ll\": \"he will\", r\"he\\'s\": \"he is\",\n",
        "        r\"i\\'d\": \"i would\", r\"i\\'ll\": \"i will\", r\"i\\'m\": \"i am\",\n",
        "        r\"isn\\'t\": \"is not\", r\"it\\'s\": \"it is\", r\"let\\'s\": \"let us\",\n",
        "        r\"mightn\\'t\": \"might not\", r\"mustn\\'t\": \"must not\", r\"shan\\'t\": \"shall not\",\n",
        "        r\"she\\'d\": \"she would\", r\"she\\'ll\": \"she will\", r\"she\\'s\": \"she is\",\n",
        "        r\"shouldn\\'t\": \"should not\", r\"that\\'s\": \"that is\", r\"there\\'s\": \"there is\",\n",
        "        r\"they\\'d\": \"they would\", r\"they\\'ll\": \"they will\", r\"they\\'re\": \"they are\",\n",
        "        r\"they\\'ve\": \"they have\", r\"we\\'d\": \"we would\", r\"we\\'re\": \"we are\",\n",
        "        r\"weren\\'t\": \"were not\", r\"what\\'ll\": \"what will\", r\"what\\'re\": \"what are\",\n",
        "        r\"what\\'s\": \"what is\", r\"what\\'ve\": \"what have\", r\"where\\'s\": \"where is\",\n",
        "        r\"who\\'d\": \"who would\", r\"who\\'ll\": \"who will\", r\"who\\'re\": \"who are\",\n",
        "        r\"who\\'s\": \"who is\", r\"who\\'ve\": \"who have\", r\"won\\'t\": \"will not\",\n",
        "        r\"wouldn\\'t\": \"would not\", r\"you\\'d\": \"you would\", r\"you\\'ll\": \"you will\",\n",
        "        r\"you\\'re\": \"you are\", r\"you\\'ve\": \"you have\"\n",
        "    }\n",
        "\n",
        "    for contraction, expansion in contractions.items():\n",
        "        cleantext = re.sub(contraction, expansion, cleantext)\n",
        "\n",
        "    # 숫자 제거\n",
        "    cleantext = NUMBER_CLEANER.sub('', cleantext)\n",
        "\n",
        "    # 소문자로 변환\n",
        "    cleantext = cleantext.lower()\n",
        "\n",
        "    # 알파벳이 아닌 문자를 공백으로 대체\n",
        "    cleantext = NON_ALPHA_CLEANER.sub(' ', cleantext)\n",
        "\n",
        "    # 연속된 공백을 하나의 공백으로 치환\n",
        "    cleantext = re.sub(r'\\s+', ' ', cleantext).strip()\n",
        "\n",
        "    return cleantext"
      ],
      "metadata": {
        "id": "OpRJIvCA53IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 전처리\n",
        "for df in [train, test, test_stg2]:\n",
        "    df['category_name'] = df['category_name'].fillna('Unknown/Unknown/Unknown')\n",
        "    df[['category1', 'category2', 'category3']] = df['category_name'].str.split('/', n=2, expand=True)\n",
        "    df[['category1', 'category2', 'category3']] = df[['category1', 'category2', 'category3']].fillna('Unknown')\n",
        "    df = df.drop(columns=['category_name'])\n",
        "    df['brand_name'] = df['brand_name'].fillna('No Brand')\n",
        "    df['item_description'] = df['item_description'].fillna('No description')\n",
        "\n",
        "    for col in ['name', 'item_description', 'brand_name', 'category1', 'category2', 'category3']:\n",
        "        df[col] = df[col].apply(preprocess)\n"
      ],
      "metadata": {
        "id": "mDHRQ_h0fzke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def robust_label_encode(train, test, test_stg2, categorical_cols):\n",
        "    le_dict = {}\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "\n",
        "        ## 모든 데이터셋의 유니크한 값을 결합.\n",
        "        unique_values = pd.concat([train[col], test[col], test_stg2[col]]).unique().tolist()\n",
        "        unique_values.append('Unknown')\n",
        "\n",
        "        ## 'Unknown' 추가\n",
        "        unique_values.append('Unknown')\n",
        "\n",
        "        ## 레이블 인코더 학습\n",
        "        le.fit(unique_values)\n",
        "\n",
        "        ## 각 데이터셋에 레이블 인코딩 적용\n",
        "        train[col] = le.transform(train[col].fillna('Unknown'))\n",
        "        test[col] = le.transform(test[col].fillna('Unknown'))\n",
        "        test_stg2[col] = le.transform(test_stg2[col].fillna('Unknown'))\n",
        "\n",
        "        le_dict[col] = le\n",
        "\n",
        "    return train, test, test_stg2, le_dict"
      ],
      "metadata": {
        "id": "MSgoEyKzHlno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "t_H9KAT00k_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 가격이 0 이상인 데이터만 추출 (훈련 데이터만)\n",
        "train = train[train['price'] > 0]"
      ],
      "metadata": {
        "id": "53UAizfGDzc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 레이블 인코딩\n",
        "categorical_cols = ['brand_name', 'category1', 'category2', 'category3']\n",
        "train, test, test_stg2, le_dict = robust_label_encode(train, test, test_stg2, categorical_cols)\n",
        "\n",
        "print(\"Label encoding completed successfully.\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def preprocess_text(df, text_columns):\n",
        "    for col in text_columns:\n",
        "        df[col] = df[col].fillna('').astype(str)\n",
        "    return df"
      ],
      "metadata": {
        "id": "UGi-XHixEeVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 텍스트 전처리 함수 적용\n",
        "text_columns = ['name', 'item_description']\n",
        "train = preprocess_text(train, text_columns)\n",
        "test = preprocess_text(test, text_columns)\n",
        "test_stg2 = preprocess_text(test_stg2, text_columns)"
      ],
      "metadata": {
        "id": "CjzG1oXAGlnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TF-IDF 벡터화\n",
        "vectorizer_name = TfidfVectorizer(max_features=1000)\n",
        "vectorizer_desc = TfidfVectorizer(min_df=10, max_features=50000)"
      ],
      "metadata": {
        "id": "jlyeLR6RGwzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 훈련 데이터 벡터화\n",
        "train_name_tfidf = vectorizer_name.fit_transform(train['name'])\n",
        "train_id_tfidf = vectorizer_desc.fit_transform(train['item_description'])"
      ],
      "metadata": {
        "id": "QRebfoKDG03X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 테스트 데이터 벡터화\n",
        "test_name_tfidf = vectorizer_name.transform(test['name'])\n",
        "test_id_tfidf = vectorizer_desc.transform(test['item_description'])\n"
      ],
      "metadata": {
        "id": "hAvnhVk75w5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 2단계 테스트 데이터 벡터화\n",
        "test_stg2_name_tfidf = vectorizer_name.transform(test_stg2['name'])\n",
        "test_stg2_id_tfidf = vectorizer_desc.transform(test_stg2['item_description'])\n",
        "\n",
        "print(\"TF-IDF vectorization completed successfully.\")"
      ],
      "metadata": {
        "id": "cGdD7OMj5_SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성 결합\n",
        "X = hstack([train_name_tfidf, train_id_tfidf, train[categorical_cols]])\n",
        "X_test = hstack([test_name_tfidf, test_id_tfidf, test[categorical_cols]])\n",
        "X_test_stg2 = hstack([test_stg2_name_tfidf, test_stg2_id_tfidf, test_stg2[categorical_cols]])\n",
        "\n",
        "y = train['price'].values\n",
        "# y = np.log1p(train['price']).values"
      ],
      "metadata": {
        "id": "6zWGUy5ABb4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성 선택\n",
        "selector = SelectKBest(f_regression, k=1000)  # 상위 1000개 특성 선택\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "X_test_stg2_selected = selector.transform(X_test_stg2)"
      ],
      "metadata": {
        "id": "eixLoM8H6MVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 분할\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "uNQxpOFGcgrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델링 및 평가 함수들\n",
        "\n",
        "# 모델 성능을 평가하는 함수\n",
        "def evaluate_model(y_test, y_pred):\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    me = max_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    ev = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "    result = {\n",
        "        'Mean Absolute Error': mae,\n",
        "        'Mean Squared Error': mse,\n",
        "        'Mean Absolute Percentage Error': mape,\n",
        "        'Median Absolute Error': medae,\n",
        "        'Max Error': me,\n",
        "        'R^2': r2,\n",
        "        'Explained Variance': ev,\n",
        "    }\n",
        "    return result"
      ],
      "metadata": {
        "id": "UyM6SoJ56TBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 탐색 공간 정의\n",
        "param_distributions = {\n",
        "    'Ridge': {'alpha': uniform(0.1, 10)},\n",
        "    'RandomForest': {\n",
        "        'n_estimators': randint(100, 500),\n",
        "        'max_depth': randint(5, 15),\n",
        "        'min_samples_split': randint(2, 11)\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': randint(100, 300), # 트리 수\n",
        "        'max_depth': randint(3, 7), # 트리 최대 깊이\n",
        "        'learning_rate': uniform(0.01, 0.2), # 학습률\n",
        "        'subsample': uniform(0.7, 0.3), # 각 트리에 사용할 샘플 비율\n",
        "        'colsample_bytree': uniform(0.7, 0.3), # 각 트리에 사용할 컬럼 비율\n",
        "        'gamma': uniform(0, 2), # 리프 노드 분할에 필요한 최소 손실감소량\n",
        "        'min_child_weight': randint(1, 5) # 리프 노드에 필요한 최소 가중치\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "yzJTD4l86WIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "models = {\n",
        "    'Ridge': Ridge(),\n",
        "    'RandomForest': RandomForestRegressor(random_state = 42),\n",
        "    'XGBoost': xgb.XGBRegressor(random_state = 42)\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# 하이퍼파라미터 튜닝 및 모델 학습\n",
        "tuned_models = {}\n",
        "predictions = {}\n",
        "predictions_stg2 = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Tuning {name}...\")\n",
        "    if name == 'LightGBM':\n",
        "        # LightGBM의 경우 GPU 사용을 위한 추가 설정\n",
        "        fit_params = {'verbose': 0, 'callbacks': [lgb.early_stopping(50)]}\n",
        "        random_search = RandomizedSearchCV(\n",
        "            model, param_distributions[name], n_iter=20, cv=3,\n",
        "            scoring='neg_mean_squared_log_error', n_jobs=1, random_state=42,\n",
        "            fit_params=fit_params\n",
        "        )\n",
        "    else:\n",
        "        random_search = RandomizedSearchCV(\n",
        "            model, param_distributions[name], n_iter=20, cv=3,\n",
        "            scoring='neg_mean_squared_log_error', n_jobs=-1, random_state=42\n",
        "        )\n",
        "\n",
        "    random_search.fit(X_train, np.log1p(y_train))\n",
        "\n",
        "    best_model = random_search.best_estimator_\n",
        "    tuned_models[name] = best_model\n",
        "\n",
        "    val_pred = np.expm1(best_model.predict(X_val))\n",
        "    test_pred = np.expm1(best_model.predict(X_test_selected))\n",
        "    test_stg2_pred = np.expm1(best_model.predict(X_test_stg2_selected))\n",
        "\n",
        "    print(f\"{name} RMSLE: {rmsle(y_val, val_pred)}\")\n",
        "    print(f\"Best parameters: {random_search.best_params_}\")\n",
        "\n",
        "    predictions[name] = test_pred\n",
        "    predictions_stg2[name] = test_stg2_pred"
      ],
      "metadata": {
        "id": "ElmlNLDL6wfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 앙상블 (단순 평균)\n",
        "ensemble_pred = np.mean(list(predictions.values()), axis=0)\n",
        "ensemble_pred_stg2 = np.mean(list(predictions_stg2.values()), axis=0)\n",
        "\n",
        "# Submission 파일 생성\n",
        "submission = pd.read_csv('sample_submission.csv')\n",
        "submission['price'] = ensemble_pred\n",
        "submission.to_csv('ensemble_submission.csv', index=False)\n",
        "\n",
        "submission_stg2 = pd.read_csv('sample_submission_stg2.csv')\n",
        "submission_stg2['price'] = ensemble_pred_stg2\n",
        "submission_stg2.to_csv('ensemble_submission_stg2.csv', index=False)\n",
        "\n",
        "print(\"Submission files created: ensemble_submission.csv and ensemble_submission_stg2.csv\")\n"
      ],
      "metadata": {
        "id": "MkG7pypH6xBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8xmBaFqimXcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "96xowNg8JYG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "# 첫 번째 서브플롯: 가격 분포\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(df['price'], bins=100 , edgecolor='white')  # range=[0,200]\n",
        "plt.title('가격 분포')\n",
        "plt.xlabel('가격')\n",
        "plt.ylabel(\"제품 수\")\n",
        "\n",
        "# 두 번째 서브플롯: 로그 변환된 가격 분포\n",
        "plt.subplot(1,2,2)\n",
        "#log_price = np.log(df['price']+1)\n",
        "log_price = np.log1p(df['price'])\n",
        "plt.hist(log_price1, bins=100, edgecolor='white')\n",
        "plt.title(\"로그 변환된 가격 분포\")\n",
        "plt.xlabel(\"log(가격+1)\")\n",
        "plt.ylabel(\"제품 수\")\n",
        "\n",
        "plt.tight_layout()  # 서브플롯 간 간격 조정\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qybk3mN5JZmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Category"
      ],
      "metadata": {
        "id": "uJ6ydhUMY2VA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# category1의 빈도수 계산\n",
        "count = df['category1'].value_counts()\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "count_df = count.reset_index()\n",
        "count_df.columns = ['category1', 'count']\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.barplot(x='category1', y='count', data=count_df, palette='husl')\n",
        "plt.title(\"카테고리1의 항목 순위\", fontsize=20)\n",
        "plt.xlabel('카테고리1', fontsize=14)\n",
        "plt.ylabel('빈도수', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "luCZeuGAZeFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 상위 3개의 카테고리 : 여성, 뷰티, 아동"
      ],
      "metadata": {
        "id": "JbYc7Bh0Zon7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# category2의 빈도수 계산\n",
        "count = df['category2'].value_counts()\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "count_df = count.reset_index()\n",
        "count_df.columns = ['category2', 'count']\n",
        "top_20_count_df = count_df.head(20)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.barplot(x='category2', y='count', data=top_20_count_df, palette='husl')\n",
        "plt.title(\"카테고리2의 항목 순위\", fontsize=20)\n",
        "plt.xlabel('카테고리2', fontsize=14)\n",
        "plt.ylabel('빈도수', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "Bl0tfojvZk6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 거의 14만 개의 제품이 운동복.\n",
        "- 운동복, 화장품, 상의와 블라우스, 신발이 가장 많은 수 기록."
      ],
      "metadata": {
        "id": "DEFWr4oHZn70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# category3의 빈도수 계산\n",
        "count = df['category3'].value_counts()\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "count_df = count.reset_index()\n",
        "count_df.columns = ['category3', 'count']\n",
        "top_20_count_df = count_df.head(20)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.barplot(x='category3', y='count', data=top_20_count_df, palette='husl')\n",
        "plt.title(\"카테고리3의 항목 순위\", fontsize=20)\n",
        "plt.xlabel('카테고리3', fontsize=14)\n",
        "plt.ylabel('빈도수', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "rBQlRqwPZ4GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 바지, 타이츠, 레깅스, 얼굴, 그리고 기타 카테고리가 하위 카테고리 레벨3에서 가장 많이 반복되는 세 가지 항목.\n",
        "\n",
        "- 데이터셋에는 화장품, 드레스 및 여성 관련 액세서리와 같이 여성과 관련된 제품이 가장 많이 포함되어 있음."
      ],
      "metadata": {
        "id": "YF4ma87uZ55l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Brand"
      ],
      "metadata": {
        "id": "XTSr6zZlZ-ZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brands =df['brand_name'].value_counts()\n",
        "top_10_brands_excluding_first = brands[1:11]\n",
        "top_10_brands_excluding_first"
      ],
      "metadata": {
        "id": "opZTouqdaBl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 상위 1개 브랜드를 제외한 상위 10개 브랜드의 빈도수 막대 그래프\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.barplot(x=top_10_brands_excluding_first.index, y=top_10_brands_excluding_first.values, palette='husl')\n",
        "plt.title('상위 10개 브랜드와 각 브랜드의 항목 수 (1위 제외)')\n",
        "plt.xlabel('브랜드명')\n",
        "plt.ylabel('수량')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HlvVua8cbdKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#가장 비싼 브랜드 찾기\n",
        "brand_median_price = df.groupby('brand_name')['price'].median().reset_index()\n",
        "\n",
        "top_25_brands = brand_median_price.sort_values(by='price', ascending=False).head(25)"
      ],
      "metadata": {
        "id": "EhvyYHXmbhvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(\n",
        "    data=top_25_brands,\n",
        "    x='price',\n",
        "    y='brand_name',\n",
        "    palette='cool'\n",
        ")\n",
        "plt.xlabel('Median Price')\n",
        "plt.ylabel('')\n",
        "plt.title('Top 25 Most Expensive Brands')\n",
        "plt.xlim(0, top_25_brands['price'].max() * 1.1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yMJddWqjbnCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Unknown' 브랜드와 그 외의 브랜드 구분\n",
        "known_brand = np.log(df.loc[df['brand_name']!='No Brand', 'price']+1)\n",
        "unknown_brand = np.log(df.loc[df['brand_name']=='No Brand', 'price']+1)\n",
        "\n",
        "# 그래프 그리기\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(known_brand, kde=True, label='Known brands', color = 'blue')\n",
        "sns.histplot(unknown_brand, kde=True, label='Unknown brand', color = 'red')\n",
        "\n",
        "plt.title('Known Brands Product Price vs Unknown Brand Product Price')\n",
        "plt.xlabel('log(price+1)')\n",
        "plt.ylabel('Count')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "39fuRWtQbofI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Item Condition"
      ],
      "metadata": {
        "id": "pSIUAoScbv2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# item_condition_id 별 빈도수 계산\n",
        "count = df['item_condition_id'].value_counts()\n",
        "\n",
        "# 상위 5개 항목으로 제한\n",
        "count = count.head(5)\n",
        "\n",
        "# 상위 5개 항목을 데이터프레임으로 변환\n",
        "count_df = count.reset_index()\n",
        "count_df.columns = ['item_condition_id', 'count']\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.barplot(x='item_condition_id', y='count', data=count_df,  palette='husl')\n",
        "plt.title('상품 상태 ID별 수량')\n",
        "plt.xlabel('상품 상태 ID')\n",
        "plt.ylabel('수량')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7GbSQrMsemUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('whitegrid')\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(x='item_condition_id', y='price', data=df, showfliers=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "63zF8k9VenM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shipping"
      ],
      "metadata": {
        "id": "E9hpNHZPeo-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='shipping', data=df)"
      ],
      "metadata": {
        "id": "x7gNkJpciQJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='shipping', y='price', data=df)\n",
        "plt.title('Mean price for shipping')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vcxMl4TZiRts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Analysis"
      ],
      "metadata": {
        "id": "rurT7jr4iUWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# NLTK 불용어 다운로드\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 불용어 목록 가져오기\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# 불용어 제거 함수\n",
        "def remove_stopwords(text):\n",
        "    words = word_tokenize(text)\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# 데이터프레임의 'name'과 'item_description' 열에 불용어 제거 적용\n",
        "df['name'] = df['name'].apply(remove_stopwords)\n",
        "df['item_description'] = df['item_description'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "GPOJE0b7ixT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer1 = TfidfVectorizer(max_features=1000)\n",
        "vectorizer1.fit(df['name'].values)\n",
        "\n",
        "df_name_tfidf = vectorizer1.transform(df['name'].values)\n",
        "# X_test_name_tfidf = vectorizer1.transform(df['name'].values)"
      ],
      "metadata": {
        "id": "3H0_SdRYiz6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer1 = TfidfVectorizer(min_df=10, max_features=5000) #ngram_range=(1,4)\n",
        "vectorizer1.fit(df['item_description'].values)\n",
        "\n",
        "df_id_tfidf = vectorizer1.transform(df['item_description'].values)\n",
        "# X_test_id_tfidf = vectorizer1.transform(df['item_description'].values)"
      ],
      "metadata": {
        "id": "jLuHGpOckzgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 스타일 설정\n",
        "plt.style.use('seaborn')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# 그래프 생성 함수\n",
        "def create_word_frequency_graph(tfidf_matrix, feature_names, title, n_top_words=20):\n",
        "    tfidf_sums = np.array(tfidf_matrix.sum(axis=0)).flatten()\n",
        "    top_indices = tfidf_sums.argsort()[-n_top_words:][::-1]\n",
        "\n",
        "    top_words = [feature_names[i] for i in top_indices]\n",
        "    top_tfidf = tfidf_sums[top_indices]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 8))\n",
        "    bars = ax.bar(range(n_top_words), top_tfidf, color=sns.color_palette(\"husl\", n_top_words))\n",
        "\n",
        "    # 막대 위에 값 표시\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.2f}',\n",
        "                ha='center', va='bottom', rotation=0)\n",
        "\n",
        "    plt.xticks(range(n_top_words), top_words, rotation=45, ha='right')\n",
        "    plt.xlabel('Words', fontsize=14)\n",
        "    plt.ylabel('TF-IDF Score', fontsize=14)\n",
        "    plt.title(title, fontsize=18, fontweight='bold')\n",
        "\n",
        "    # 격자 추가\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 'name' 필드에 대한 그래프 생성\n",
        "create_word_frequency_graph(df_name_tfidf, vectorizer1.get_feature_names_out(),\n",
        "                            \"Top 20 Words in Name Field\")\n",
        "\n",
        "# 'item_description' 필드에 대한 그래프 생성\n",
        "create_word_frequency_graph(df_id_tfidf, vectorizer1.get_feature_names_out(),\n",
        "                            \"Top 20 Words in Item Description Field\")"
      ],
      "metadata": {
        "id": "xEh5z3wblD32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lj3pZ1mBlgoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wkasW_GGlj_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Model (우선 돌려보기)"
      ],
      "metadata": {
        "id": "h4Bfzjon1sO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_model1 = df.copy()\n",
        "test_model1  = df_test.copy()"
      ],
      "metadata": {
        "id": "pIgjf3p97IY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## train_id, test_id는 제거하기\n",
        "train_model1, _ = drop_id_feature(train_model1, 'train_id')\n",
        "test_model1, _  = drop_id_feature(test_model1, 'test_id')"
      ],
      "metadata": {
        "id": "rn6h1Kkv-YGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 숫자행 제외하고 제거하기. (240722 14:47 기준 이상치처리를 하지 않아 숫자형은 item, shipping 뿐)\n",
        "train_model1 = train_model1.drop(columns=train_model1.select_dtypes(exclude=[np.number]).columns)\n",
        "test_model1  = test_model1.drop(columns=test_model1.select_dtypes(exclude=[np.number]).columns)\n",
        "df_dtypes(train_model1)"
      ],
      "metadata": {
        "id": "FyMGePVg-g-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## test set : 20%\n",
        "X_train, X_test, y_train, y_test = split_data_train_test(train_model1, target_feature)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "S1PGaKT2-k10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Ridge, LinearRegreesion, 의사결정나무회귀 돌려보기\n",
        "models_result1 = run_models(baseline_models, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "qZ7CtggY-16p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_result1\n",
        "## 아무런 처리를 하지 않고 출력했기 때문에 성능이 매우 안 좋은 것을 확인(R^2가 0.01 수준이다.)"
      ],
      "metadata": {
        "id": "US6CNDiT_ESg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models1 = get_best_model(models_result1, baseline_models, 'Mean Squared Error')\n",
        "print('Best Model of Baseline Models is:', best_models1.__class__.__name__)\n",
        "## 0.012인 DecisionTreeRegressor가 높게 나옴."
      ],
      "metadata": {
        "id": "5RzKocJn_GMo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}